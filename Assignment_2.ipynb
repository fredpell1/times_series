{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - MATH60837A\n",
    "William Bourque - 11359215\n",
    "\n",
    "Frederic Pelletier - 11359258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing dependencies (only needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas\n",
    "%pip install statsmodels\n",
    "%pip install arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf, pacf, q_stat\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import chi2\n",
    "from arch import arch_model\n",
    "from scipy.optimize import minimize, LinearConstraint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "df['log_HP'] = np.log(df['QCAR628BIS'])\n",
    "df['diff_HP'] = df['log_HP'].diff()\n",
    "df = df.dropna()\n",
    "yt = df['diff_HP']\n",
    "zt = df['log_HP']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1.Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a) Estimate all 4 models by maximum likelihood, report the estimation results, and verify if the stationarity conditions and invertibility conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(model: ARIMA):\n",
    "    p,_,q = model.specification.order\n",
    "    r = max(p,q)\n",
    "    phi_matrix = np.zeros((r,r))\n",
    "    phis = model.arparams\n",
    "    phi_matrix[0,:] = np.pad(model.arparams, (0, r - len(phis)), mode='constant')\n",
    "    np.fill_diagonal(phi_matrix[1:p,:p],1)\n",
    "    eigenvalues = np.linalg.eigvals(phi_matrix)\n",
    "    print(phi_matrix)\n",
    "    return np.all(np.abs(eigenvalues) < 1)\n",
    "\n",
    "def test_invertibility(model:ARIMA):\n",
    "    p,_,q = model.specification.order\n",
    "    r = max(p,q)\n",
    "    theta_matrix = np.zeros((r,r))\n",
    "    thetas = model.maparams\n",
    "    theta_matrix[0,:] = np.pad(thetas, (0,r - len(thetas)), mode='constant')\n",
    "    np.fill_diagonal(theta_matrix[1:q,:q],1)\n",
    "    eigenvalues = np.linalg.eigvals(theta_matrix)\n",
    "    print(theta_matrix)\n",
    "    return np.all(np.abs(eigenvalues) < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we will be testing for stationarity and invertibility, we do not force the\n",
    "# algorithm to ensure either of them\n",
    "ar4 = ARIMA(yt, order=(4,0,0), enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "arma41 = ARIMA(yt, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "arma42 = ARIMA(yt, order=(4,0,2),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "\n",
    "for name,model in {'ar(4)': ar4,'arma(4,1)': arma41,'arma(4,2)': arma42}.items():\n",
    "    stationary = test_stationarity(model)\n",
    "    invertible = test_invertibility(model)\n",
    "    print(model.summary())\n",
    "    print(f'{name} is {\"stationary\" if stationary else \"not stationary\"}')\n",
    "    print(f'{name} is {\"invertible\" if invertible else \"not invertible\"}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "All models are both stationary and invertible since the eigenvalues of their respective phi and theta matrices all have modules less than 1. However, for all models, some parameters \n",
    "do not have a p-value < 0.05, meaning there is no strong statistical evidence that the parameter should be different than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Select a model among the 3 using the BIC criterion. Perform likelihood ratio tests (using a 5% significance level) to discriminate between that model and possible alternatives among the remaining 2. Evaluate the white noise hypothesis for the residuals to justify the selection of a final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the BIC creterion for each model\n",
    "print(f'BIC for AR(4): {ar4.bic}')\n",
    "print(f'BIC for ARMA(4,1): {arma41.bic}')\n",
    "print(f'BIC for ARMA(4,2): {arma42.bic}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define a function to help us perform the test\n",
    "def likelihood_ratio_test(l1,l0,k, alpha):\n",
    "    statistic = 2*(l1 - l0)\n",
    "    critical_value = chi2.ppf(1 - alpha, k)\n",
    "    print(f'{statistic=}, {critical_value=}')\n",
    "    print('p-value:',1 - chi2.cdf(statistic, k)) # P(chi2 > statistic)\n",
    "    return statistic > critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_first_test = None\n",
    "model_from_second_test = None\n",
    "can_reject_null = likelihood_ratio_test(arma41.llf, ar4.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the AMRA(4,1)')\n",
    "    model_from_first_test = arma41\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the AR(1)')\n",
    "    model_from_first_test = ar4\n",
    "\n",
    "can_reject_null = likelihood_ratio_test(arma42.llf, model_from_first_test.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the ARMA(4,2)')\n",
    "    model_from_second_test = arma42\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the ARMA(4,1)')\n",
    "    model_from_second_test = arma41\n",
    "\n",
    "selected_model = model_from_second_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the Lyung-Box test to make sure the residuals of the model are white noise\n",
    "residuals = selected_model.resid\n",
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "acf(residuals,nlags=20)\n",
    "\n",
    "if h1.mean() == 0:\n",
    "    chosen_model = selected_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "Using the BIC creterion the selected model is the ARMA(4,1), because its value of -898.96 was the smallest among the three models. To verify the potency of this result we perform the likelihood ratio test. The first test uses the AR(4) as null hypothesis angainst the ARMA(4,1). The p-value is smaller than the chosen alpha meaning we reject the null and select the ARMA(4,1). The second test uses the selected model from the first test, ARMA(4,1) as the null against the ARMA(4,2). The p-value is greater than the chosen alpha meaning we cannot reject the null and select once again the ARMA(4,1). To verify the white noise hypothesis for the residuals we perform the Lyung-Box test. The test is concluent, we cannot reject the null for the first 18 lags, it suggests that the residuals are white noise and the model can bu useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Dynamic Response and forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) For the selected model, evaluate the dynamic response for an horizon of 10 periods following a positive shock of size sigma = 1.15 occuring at the first period of the horizon, and explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_model.params)\n",
    "plt.plot(chosen_model.impulse_responses(10,[1.15]), label='response')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Response value')\n",
    "plt.title('Dynamic response following a shock of 1.15')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "We can see that following the shock, the dynamic response quickly fades to 0. However, it is not strictly decreasing, which makes sense given the polynomial nature of the dynamic response equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) For the selected model, evaluate the dynamic response for an horizon of 10 periods following a positive shock of size occurs during 3 consecutive periods of the horizon (t, t+1, t+2). Plot the impulse response function, showing the dynamic response for an horizon of 20 periods following these shocks, and explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to use the definition with psi_0 = psi_1 = psi_2 = 1.15\n",
    "n_periods = 20\n",
    "shocks = [1.15,1.15,1.15]\n",
    "total_n_periods = n_periods + len(shocks)\n",
    "responses = np.append(shocks,[0] * n_periods)\n",
    "p = len(chosen_model.arparams)\n",
    "q = len(chosen_model.maparams)\n",
    "for i in range(len(shocks), total_n_periods):\n",
    "    p_indices = [i - j for j in range(1,p+1)]\n",
    "    q_indices = [i - j for j in range(1,q+1)]\n",
    "    prev_shocks = [responses[pi] if pi >= 0 else 0 for pi in p_indices]\n",
    "    prev_noises = [1 if qi == 0 else 0 for qi in q_indices]\n",
    "    responses[i] = np.dot(prev_shocks,chosen_model.arparams) - np.dot(prev_noises, chosen_model.maparams) + (1 if i == 0 else 0)\n",
    "plt.plot(responses[3:],  label=\"Response of y to 3 Consecutive Shocks\")\n",
    "\n",
    "# Plot impulse responses\n",
    "plt.axhline(y=0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Response\")\n",
    "plt.title(\"Impulse Response of ARMA(4,1) with 3 Consecutive Shocks of 1.15\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "We can see the the dynamic response takes a longer time before reaching 0, oscillating up and down the 0 line. This is due to the fact that the high-valued shocks, i.e. those with value 1.15, get picked up longer in the recursion, increasing the value of several of the next iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c) Forecasting: Split the sample into a training sample and a holdout sample. The holdout sample should consist of the last 34 observations \n",
    "\n",
    " - Re-estimate the selected model using only the training sample\n",
    " - Calculate the 1-step ahead forecasts for the stationarized series\n",
    " - Plot these forecasts along with the actual series on the same graph for the period covered by the hold-out sample\n",
    " - Now calculate and plot the level (as opposed to first difference) of the variable zt against its 1-step ahead forecasts from the 2 models and from the naive forecast E(zt+1) = zt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = yt[:-34]\n",
    "test_set = yt[-34:] #last 34 data points\n",
    "forecast_model_init = ARIMA(training_set, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "initial_chunk = test_set.iloc[:4]\n",
    "forecast_model = forecast_model_init.extend(initial_chunk)\n",
    "\n",
    "\n",
    "y_forecast_values = []\n",
    "forecast_dates = test_set.index[4:]  # Get the dates for forecasts\n",
    "\n",
    "for i in range(4, len(test_set)):\n",
    "    next_value = test_set.iloc[i]  \n",
    "\n",
    "    # Generate 1-step-ahead forecast\n",
    "    forecast_value = forecast_model.forecast(steps=1)[0]\n",
    "    y_forecast_values.append(forecast_value)\n",
    "\n",
    "    # Extend the model with the new observed value\n",
    "    forecast_model = forecast_model.extend([next_value])\n",
    "\n",
    "# Convert forecasts into a Pandas DataFrame\n",
    "y_forecast_df = pd.DataFrame({\"Forecast\": y_forecast_values}, index=forecast_dates)\n",
    "\n",
    "# Print results\n",
    "plt.plot(y_forecast_df, label='forecast of yt')\n",
    "plt.plot(test_set[4:], label='yt')\n",
    "plt.legend()\n",
    "plt.title('Forecasted value of yt vs yt')\n",
    "plt.ylabel('yt')\n",
    "plt.xlabel('date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_training_set = zt[:-34]\n",
    "z_test_set = zt[-34:]\n",
    "\n",
    "z_forecast_model_init = ARIMA(z_training_set, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "initial_chunk = np.asarray(z_test_set.iloc[:4])\n",
    "z_forecast_model = z_forecast_model_init.extend(initial_chunk)\n",
    "\n",
    "z_forecast_values = []\n",
    "\n",
    "forecast_dates = z_test_set.index[4:]  # Get the dates for forecasts\n",
    "\n",
    "for i in range(4, len(z_test_set)):\n",
    "    next_value = z_test_set.iloc[i]  \n",
    "\n",
    "    # Generate 1-step-ahead forecast\n",
    "\n",
    "    z_forecast_value = z_forecast_model.forecast(steps=1)[0]\n",
    "    z_forecast_values.append(z_forecast_value)\n",
    "\n",
    "\n",
    "    # Extend the model with the new observed value\n",
    "    z_forecast_model = forecast_model.extend([next_value])\n",
    "# Convert forecasts into a Pandas DataFrame\n",
    "z_forecast_df = pd.DataFrame({\"Forecast\": z_forecast_values}, index=forecast_dates)\n",
    "\n",
    "\n",
    "plt.plot(z_forecast_df, label='forecast of zt with z-model')\n",
    "plt.plot(z_test_set[4:], label='zt')\n",
    "plt.plot(z_test_set.shift(1).dropna()[3:], label='forecast of zt with dummy model')\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.title('Forecasted value of zt vs zt')\n",
    "plt.ylabel('zt')\n",
    "plt.xlabel('date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d) Report the Mean-Squared Error for the selected model using only the hold-out sample of 34 observations to evaluate the forecast performance. Compare these statistics to those from the naive forecast. What model should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = ((test_set[4:] - y_forecast_values) ** 2).mean()\n",
    "mse_naive = ((test_set[4:] - test_set.shift(1).dropna()[3:]) ** 2).mean()\n",
    "print(mse_model, mse_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Further improvements by modelling the conditionnal variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a) Plot the autocorrelation and partial autocorrelation functions of y_t squared. What can you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_squared = pow(yt,2)\n",
    "acf_vector = acf(yt_squared, nlags = 20)\n",
    "pacf_vector = pacf(yt_squared, nlags = 20)\n",
    "\n",
    "plt.plot(acf_vector, label = 'Autocorrelation')\n",
    "plt.plot(pacf_vector, label = 'Partial autocorrelation')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title('Autocorrelation and Partial Autocorrelation')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b) Estimate the ARCH(1) and GARCH(1,1) versions of the model selected in part 1 using only the training sample, and report the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately, there are no python packages supporting ARMA - GARCH models, so we need to obtain the parameters \n",
    "# by optimizing the log-likelihood function manually\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def arma_garch_loglike(params, y, p, q, r, s):\n",
    "\n",
    "    n = len(y)\n",
    "    \n",
    "    c = params[0]  \n",
    "    phi = params[1:p+1]  \n",
    "    theta = params[p+1:p+q+1]  \n",
    "    alpha0 = params[p+q+1]  \n",
    "    alpha = params[p+q+2:p+q+2+r]  \n",
    "    beta = params[p+q+2+r:p+q+2+r+s] \n",
    "\n",
    "    ht = np.ones(n) * np.var(y)\n",
    "    ut = np.zeros(n)  \n",
    "\n",
    "    \n",
    "    for t in range(max(p, q, r, s), n):\n",
    "        # ARMA(p,q) equation\n",
    "        arma_mean = c\n",
    "        if p > 0:\n",
    "            arma_mean += np.dot(phi, y[t-p:t])  # AR terms\n",
    "        if q > 0:\n",
    "            arma_mean += np.dot(theta, ut[t-q:t])  # MA terms\n",
    "        \n",
    "        # Compute residual\n",
    "        ut[t] = y[t] - arma_mean\n",
    "        \n",
    "        # Compute GARCH(r,s) variance equation\n",
    "        ht[t] = alpha0\n",
    "        if r > 0:\n",
    "            ht[t] += np.dot(alpha, ut[t-r:t]**2)  # ARCH terms\n",
    "        if s > 0:\n",
    "            ht[t] += np.dot(beta, ht[t-s:t])  # GARCH terms\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # Compute log-likelihood, dropping the constant term\n",
    "    loglike = -0.5 * np.sum(np.log(ht[max(p, q, r, s):]) + (ut[max(p, q, r, s):]**2 / ht[max(p, q, r, s):]))\n",
    "    \n",
    "    return -loglike  # We minimize negative log-likelihood, which is mathematically equivalent to maximing log-likelihood, to avoid overflow\n",
    "\n",
    "def estimate_arma_garch(y, p, q, r, s):\n",
    "\n",
    "    # Parameter estimation\n",
    "\n",
    "    initial_params = [forecast_model_init.params['const'],*forecast_model_init.arparams, *forecast_model_init.maparams, *np.random.uniform(0,1,1), *np.random.uniform(0,1,r), *np.random.uniform(0,1,s)]\n",
    "    \n",
    "\n",
    "    #        arma(p,q) bounds          alpha0 bound  alpha bound  beta bound\n",
    "    bounds = [(None,None)] * (p+q+1) + [(1e-8,None)] + [(0,1)] * r + [(0,1)] * s\n",
    "    constraints = [0] * (p+q+1) + [0] + [1] * r + [1] * s #to ensure 0 < alpha + beta < 1\n",
    "    result = minimize(arma_garch_loglike, initial_params, args=(y.values, p, q, r, s), bounds=bounds, constraints=LinearConstraint(constraints,0,1)) \n",
    "\n",
    "    print(result.success, result.message)\n",
    "    # Extract optimized parameters\n",
    "    estimated_params = result.x\n",
    "    return {\n",
    "        \"c\": estimated_params[0],\n",
    "        \"phi\": estimated_params[1:p+1],\n",
    "        \"theta\": estimated_params[p+1:p+q+1],\n",
    "        \"alpha0\": estimated_params[p+q+1],\n",
    "        \"alpha\": estimated_params[p+q+2:p+q+2+r],\n",
    "        \"beta\": estimated_params[p+q+2+r:p+q+2+r+s],\n",
    "        \"log_likelihood\": -result.fun\n",
    "    }\n",
    "\n",
    "# the optimization algorithm tends to hit a local minima from time to time, so we will do the \n",
    "# process 10 times and mix the max value for both models\n",
    "arch_model_fit = estimate_arma_garch(training_set,4,1,1,0)\n",
    "garch_model_fit = estimate_arma_garch(training_set,4,1,1,1)\n",
    "\n",
    "for i in range(9):\n",
    "    curr_arch_model_fit = estimate_arma_garch(training_set,4,1,1,0)\n",
    "    if curr_arch_model_fit['log_likelihood'] > arch_model_fit['log_likelihood']:\n",
    "        arch_model_fit = curr_arch_model_fit\n",
    "    curr_garch_model_fit = estimate_arma_garch(training_set,4,1,1,1)\n",
    "    if curr_garch_model_fit['log_likelihood'] > garch_model_fit['log_likelihood']:\n",
    "        garch_model_fit = curr_garch_model_fit\n",
    "\n",
    "print('arch_model:', arch_model_fit)\n",
    "print('garch_model_fit', garch_model_fit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Perform likelihood ratio tests to select one model among the original ARMA model selected in part 1, its ARCH(1) alternative, and its GARCH(1,1) alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_llr = None\n",
    "can_reject_null = likelihood_ratio_test(garch_model_fit['log_likelihood'], arch_model_fit['log_likelihood'], 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we select the GARCH(1,1)')\n",
    "    model_from_llr = garch_model_fit\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the ARCH(1)')\n",
    "    model_from_llr = arch_model_fit\n",
    "\n",
    "can_reject_null = likelihood_ratio_test(model_from_llr['log_likelihood'],forecast_model_init.llf,2,0.05 )\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we select the ARMA(4,1) - GARCH(1,1)')\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the ARMA(4,1)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.d) Perform a specification test on the residuals of the ARCH(1) and GARCH(1,1) components. What is the best model for the conditional variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arma_garch_specification_test(params, y, p, q, r, s):\n",
    "\n",
    "    n = len(y)\n",
    "    \n",
    "    c = params['c']  \n",
    "    phi = params['phi']  \n",
    "    theta = params['theta']  \n",
    "    alpha0 = params['alpha0']  \n",
    "    alpha = params['alpha']  \n",
    "    beta = params['beta'] \n",
    "\n",
    "    ht = np.ones(n) * np.var(y)\n",
    "    ut = np.zeros(n)  \n",
    "    for t in range(max(p, q, r, s), n):\n",
    "        # ARMA(p,q) equation\n",
    "        arma_mean = c\n",
    "        if p > 0:\n",
    "            arma_mean += np.dot(phi, y[t-p:t])  # AR terms\n",
    "        if q > 0:\n",
    "            arma_mean += np.dot(theta, ut[t-q:t])  # MA terms\n",
    "        \n",
    "        # Compute residual\n",
    "        ut[t] = y[t] - arma_mean\n",
    "        \n",
    "        # Compute GARCH(r,s) variance equation\n",
    "        ht[t] = alpha0\n",
    "        if r > 0:\n",
    "            ht[t] += np.dot(alpha, ut[t-r:t]**2)  # ARCH terms\n",
    "        if s > 0:\n",
    "            ht[t] += np.dot(beta, ht[t-s:t])  # GARCH terms\n",
    "\n",
    "    return ut**2 / ht\n",
    "\n",
    "zt_arch = arma_garch_specification_test(arch_model_fit, training_set, 4,1,1,0)\n",
    "zt_garch = arma_garch_specification_test(garch_model_fit, training_set, 4,1,1,1)\n",
    "\n",
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(zt_arch[4:], lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "plt.plot(acf(zt_arch[4:],nlags=20), label='acf(zt_arch)')\n",
    "\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(zt_garch[4:], lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "plt.plot(acf(zt_garch[4:],nlags=20), label='acf(zt_garch)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.e) For these two new models and the model studied in Part 2, plot the impulse response functions of the second case described in Part 2. How different are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to use the definition with psi_0 = psi_1 = psi_2 = 1.15\n",
    "n_periods = 20\n",
    "shocks = [1.15,1.15,1.15]\n",
    "\n",
    "def impulse_response_arma_garch(params,n_periods,shocks):\n",
    "    total_n_periods = n_periods + len(shocks)\n",
    "    responses = np.append(shocks,[0] * n_periods)\n",
    "    p = len(params['phi'])\n",
    "    q = len(params['theta'])\n",
    "    for i in range(len(shocks), total_n_periods):\n",
    "        p_indices = [i - j for j in range(1,p+1)]\n",
    "        q_indices = [i - j for j in range(1,q+1)]\n",
    "        prev_shocks = [responses[pi] if pi >= 0 else 0 for pi in p_indices]\n",
    "        prev_noises = [1 if qi == 0 else 0 for qi in q_indices]\n",
    "        responses[i] = np.dot(prev_shocks,params['phi']) - np.dot(prev_noises, params['theta']) + (1 if i == 0 else 0)\n",
    "    return responses\n",
    "\n",
    "arch_responses = impulse_response_arma_garch(arch_model_fit,20,shocks)\n",
    "garch_responses = impulse_response_arma_garch(garch_model_fit, 20, shocks)\n",
    "plt.plot(arch_responses[3:],  label=\"Dynamic response for ARMA(4,1) - ARCH(1)\")\n",
    "plt.plot(garch_responses[3:], label=\"Dynamic response for ARMA(4,1) - GARCH(1,1)\")\n",
    "plt.plot(responses[3:], label=\"Dynamic response for ARMA(4,1)\")\n",
    "# Plot impulse responses\n",
    "plt.axhline(y=0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Response\")\n",
    "plt.title(\"Impulse Response of ARMA(4,1) with 3 Consecutive Shocks of 1.15\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.f)Like in Part 2, plot the 1-step ahead forecasts for for the period covered by the holdout sample. Compare them with those obtained in Part 2. Are they different from before? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arma_garch_forecast(params, y, p,q,r,s):\n",
    "    n = len(y)\n",
    "    forecast_dates = y.index[max(p,q,r,s):]\n",
    "    c = params['c']  \n",
    "    phi = params['phi']  \n",
    "    theta = params['theta']  \n",
    "    ut = np.zeros(n)\n",
    "    forecasts = []  \n",
    "    for t in range(max(p, q, r, s), n):\n",
    "        # ARMA(p,q) equation\n",
    "        forecast = c\n",
    "        if p > 0:\n",
    "            forecast += np.dot(phi, y[t-p:t])  # AR terms\n",
    "        if q > 0:\n",
    "            forecast += np.dot(theta, ut[t-q:t])  # MA terms\n",
    "        ut[t] = y[t] - forecast\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "    forecast_df = pd.DataFrame({\"Forecast\": forecasts}, index=forecast_dates)\n",
    "        \n",
    "    return forecast_df\n",
    "\n",
    "\n",
    "arch_forecast = arma_garch_forecast(arch_model_fit, test_set, 4,1,1,0)\n",
    "garch_forecast = arma_garch_forecast(garch_model_fit,test_set,4,1,1,1)\n",
    "plt.plot(arch_forecast, label='ARMA(4,1) - ARCH(1) forecast of yt')\n",
    "plt.plot(garch_forecast, label='ARMA(4,1) - GARCH(1) forecast of yt')\n",
    "plt.plot(y_forecast_df, label='ARMA(4,1) forecast of yt')\n",
    "plt.plot(test_set[4:], label='yt')\n",
    "plt.legend()\n",
    "plt.title('Forecasted value of yt vs yt')\n",
    "plt.ylabel('yt')\n",
    "plt.xlabel('date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((test_set[4:] - arch_forecast['Forecast']) ** 2 ).mean()) #arch\n",
    "print(((test_set[4:] - garch_forecast['Forecast']) ** 2 ).mean()) #garch\n",
    "print(((test_set[4:] - y_forecast_values) ** 2).mean()) #arma(4,1)\n",
    "print(((test_set[4:] - test_set.shift(1).dropna()[3:]) ** 2).mean()) #naive\n",
    "print((test_set[4:]**2).mean()) # forecast of 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
