{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - MATH60837A\n",
    "William Bourque - 11359215\n",
    "\n",
    "Frederic Pelletier - 11359258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing dependencies (only needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "df['log_HP'] = np.log(df['QCAR628BIS'])\n",
    "df['diff_HP'] = df['log_HP'].diff()\n",
    "df = df.dropna()\n",
    "yt = df['diff_HP']\n",
    "zt = df['log_HP']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1.Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a) Estimate all 4 models by maximum likelihood, report the estimation results, and verify if the stationarity conditions and invertibility conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(model: ARIMA):\n",
    "    p,_,q = model.specification.order\n",
    "    r = max(p,q)\n",
    "    phi_matrix = np.zeros((r,r))\n",
    "    phis = model.arparams\n",
    "    phi_matrix[0,:] = np.pad(model.arparams, (0, r - len(phis)), mode='constant')\n",
    "    np.fill_diagonal(phi_matrix[1:p,:p],1)\n",
    "    eigenvalues = np.linalg.eigvals(phi_matrix)\n",
    "    print(phi_matrix)\n",
    "    return np.all(np.abs(eigenvalues) < 1)\n",
    "\n",
    "def test_invertibility(model:ARIMA):\n",
    "    p,_,q = model.specification.order\n",
    "    r = max(p,q)\n",
    "    theta_matrix = np.zeros((r,r))\n",
    "    thetas = model.maparams\n",
    "    theta_matrix[0,:] = np.pad(thetas, (0,r - len(thetas)), mode='constant')\n",
    "    np.fill_diagonal(theta_matrix[1:q,:q],1)\n",
    "    eigenvalues = np.linalg.eigvals(theta_matrix)\n",
    "    print(theta_matrix)\n",
    "    return np.all(np.abs(eigenvalues) < 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we will be testing for stationarity and invertibility, we do not force the\n",
    "# algorithm to ensure either of them\n",
    "ar4 = ARIMA(yt, order=(4,0,0), enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "arma41 = ARIMA(yt, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "arma42 = ARIMA(yt, order=(4,0,2),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "\n",
    "for name,model in {'ar(4)': ar4,'arma(4,1)': arma41,'arma(4,2)': arma42}.items():\n",
    "    stationary = test_stationarity(model)\n",
    "    invertible = test_invertibility(model)\n",
    "    print(model.summary())\n",
    "    print(f'{name} is {\"stationary\" if stationary else \"not stationary\"}')\n",
    "    print(f'{name} is {\"invertible\" if invertible else \"not invertible\"}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "All models are both stationary and invertible since the eigenvalues of their respective phi and theta matrices all have modules less than 1. However, for all models, some parameters \n",
    "do not have a p-value < 0.05, meaning there is no strong statistical evidence that the parameter should be different than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Select a model among the 3 using the BIC criterion. Perform likelihood ratio tests (using a 5% significance level) to discriminate between that model and possible alternatives among the remaining 2. Evaluate the white noise hypothesis for the residuals to justify the selection of a final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the BIC creterion for each model\n",
    "print(f'BIC for AR(4): {ar4.bic}')\n",
    "print(f'BIC for ARMA(4,1): {arma41.bic}')\n",
    "print(f'BIC for ARMA(4,2): {arma42.bic}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first define a function to help us perform the test\n",
    "def likelihood_ratio_test(l1,l0,k, alpha):\n",
    "    statistic = 2*(l1 - l0)\n",
    "    critical_value = chi2.ppf(1 - alpha, k)\n",
    "    print(f'{statistic=}, {critical_value=}')\n",
    "    print('p-value:',1 - chi2.cdf(statistic, k)) # P(chi2 > statistic)\n",
    "    return statistic > critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_first_test = None\n",
    "model_from_second_test = None\n",
    "can_reject_null = likelihood_ratio_test(arma41.llf, ar4.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the AMRA(4,1)')\n",
    "    model_from_first_test = arma41\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the AR(1)')\n",
    "    model_from_first_test = ar4\n",
    "\n",
    "can_reject_null = likelihood_ratio_test(arma42.llf, model_from_first_test.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the ARMA(4,2)')\n",
    "    model_from_second_test = arma42\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the ARMA(4,1)')\n",
    "    model_from_second_test = arma41\n",
    "\n",
    "selected_model = model_from_second_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform the Lyung-Box test to make sure the residuals of the model are white noise\n",
    "residuals = selected_model.resid\n",
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "acf(residuals,nlags=20)\n",
    "\n",
    "if h1.mean() == 0:\n",
    "    chosen_model = selected_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "Using the BIC creterion the selected model is the ARMA(4,1), because its value of -898.96 was the smallest among the three models. To verify the potency of this result we perform the likelihood ratio test. The first test uses the AR(4) as null hypothesis angainst the ARMA(4,1). The p-value is smaller than the chosen alpha meaning we reject the null and select the ARMA(4,1). The second test uses the selected model from the first test, ARMA(4,1) as the null against the ARMA(4,2). The p-value is greater than the chosen alpha meaning we cannot reject the null and select once again the ARMA(4,1). To verify the white noise hypothesis for the residuals we perform the Lyung-Box test. The test is concluent, we cannot reject the null for the first 18 lags, it suggests that the residuals are white noise and the model can bu useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Dynamic Response and forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) For the selected model, evaluate the dynamic response for an horizon of 10 periods following a positive shock of size sigma = 1.15 occuring at the first period of the horizon, and explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chosen_model.params)\n",
    "plt.plot(chosen_model.impulse_responses(10,[1.15]), label='response')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Response value')\n",
    "plt.title('Dynamic response following a shock of 1.15')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "\n",
    "We can see that following the shock, the dynamic response quickly fades to 0. However, it is not strictly decreasing, which makes sense given the polynomial nature of the dynamic response equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) For the selected model, evaluate the dynamic response for an horizon of 10 periods following a positive shock of size occurs during 3 consecutive periods of the horizon (t, t+1, t+2). Plot the impulse response function, showing the dynamic response for an horizon of 20 periods following these shocks, and explain what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to use the definition with psi_0 = psi_1 = psi_2 = 1.15\n",
    "n_periods = 20\n",
    "shocks = [1.15,1.15,1.15]\n",
    "total_n_periods = n_periods + len(shocks)\n",
    "responses = np.append(shocks,[0] * n_periods)\n",
    "p = len(chosen_model.arparams)\n",
    "q = len(chosen_model.maparams)\n",
    "for i in range(len(shocks), total_n_periods):\n",
    "    p_indices = [i - j for j in range(1,p+1)]\n",
    "    q_indices = [i - j for j in range(1,q+1)]\n",
    "    prev_shocks = [responses[pi] if pi >= 0 else 0 for pi in p_indices]\n",
    "    prev_noises = [1 if qi == 0 else 0 for qi in q_indices]\n",
    "    responses[i] = np.dot(prev_shocks,chosen_model.arparams) - np.dot(prev_noises, chosen_model.maparams) + (1 if i == 0 else 0)\n",
    "plt.plot(responses[3:],  label=\"Response of y to 3 Consecutive Shocks\")\n",
    "\n",
    "# Plot impulse responses\n",
    "plt.axhline(y=0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Response\")\n",
    "plt.title(\"Impulse Response of ARMA(4,1) with 3 Consecutive Shocks of 1.15\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "We can see the the dynamic response takes a longer time before reaching 0, oscillating up and down the 0 line. This is due to the fact that the high-valued shocks, i.e. those with value 1.15, get picked up longer in the recursion, increasing the value of several of the next iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c) Forecasting: Split the sample into a training sample and a holdout sample. The holdout sample should consist of the last 34 observations \n",
    "\n",
    " - Re-estimate the selected model using only the training sample\n",
    " - Calculate the 1-step ahead forecasts for the stationarized series\n",
    " - Plot these forecasts along with the actual series on the same graph for the period covered by the hold-out sample\n",
    " - Now calculate and plot the level (as opposed to first difference) of the variable zt against its 1-step ahead forecasts from the 2 models and from the naive forecast E(zt+1) = zt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = yt[:-34]\n",
    "test_set = yt[-34:] #last 34 data points\n",
    "forecast_model_init = ARIMA(training_set, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "initial_chunk = test_set.iloc[:4]\n",
    "forecast_model = forecast_model_init.extend(initial_chunk)\n",
    "\n",
    "\n",
    "y_forecast_values = []\n",
    "forecast_dates = test_set.index[4:]  # Get the dates for forecasts\n",
    "\n",
    "for i in range(4, len(test_set)):\n",
    "    next_value = test_set.iloc[i]  \n",
    "\n",
    "    # Generate 1-step-ahead forecast\n",
    "    forecast_value = forecast_model.forecast(steps=1)[0]\n",
    "    y_forecast_values.append(forecast_value)\n",
    "\n",
    "    # Extend the model with the new observed value\n",
    "    forecast_model = forecast_model.extend([next_value])\n",
    "\n",
    "# Convert forecasts into a Pandas DataFrame\n",
    "forecast_df = pd.DataFrame({\"Forecast\": y_forecast_values}, index=forecast_dates)\n",
    "\n",
    "# Print results\n",
    "plt.plot(forecast_df, label='forecast of yt')\n",
    "plt.plot(test_set[4:], label='yt')\n",
    "plt.legend()\n",
    "plt.title('Forecasted value of yt vs yt')\n",
    "plt.ylabel('yt')\n",
    "plt.xlabel('date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_training_set = zt[:-34]\n",
    "z_test_set = zt[-34:]\n",
    "\n",
    "forecast_model_init = ARIMA(training_set, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "z_forecast_model_init = ARIMA(z_training_set, order=(4,0,1),enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "initial_chunk = np.asarray(z_test_set.iloc[:4])\n",
    "forecast_model = forecast_model_init.extend(initial_chunk)\n",
    "z_forecast_model = z_forecast_model_init.extend(initial_chunk)\n",
    "\n",
    "forecast_values = []\n",
    "z_forecast_values = []\n",
    "\n",
    "forecast_dates = z_test_set.index[4:]  # Get the dates for forecasts\n",
    "\n",
    "for i in range(4, len(z_test_set)):\n",
    "    next_value = z_test_set.iloc[i]  \n",
    "\n",
    "    # Generate 1-step-ahead forecast\n",
    "    forecast_value = forecast_model.forecast(steps=1)[0]\n",
    "    forecast_values.append(forecast_value)\n",
    "\n",
    "    z_forecast_value = z_forecast_model.forecast(steps=1)[0]\n",
    "    z_forecast_values.append(z_forecast_value)\n",
    "\n",
    "\n",
    "    # Extend the model with the new observed value\n",
    "    forecast_model = forecast_model.extend([next_value])\n",
    "    z_forecast_model = forecast_model.extend([next_value])\n",
    "# Convert forecasts into a Pandas DataFrame\n",
    "forecast_df = pd.DataFrame({\"Forecast\": forecast_values}, index=forecast_dates)\n",
    "z_forecast_df = pd.DataFrame({\"Forecast\": z_forecast_values}, index=forecast_dates)\n",
    "\n",
    "\n",
    "plt.plot(z_forecast_df, label='forecast of zt with z-model')\n",
    "plt.plot(forecast_df, label='forecast of zt')\n",
    "plt.plot(z_test_set[4:], label='zt')\n",
    "plt.plot(z_test_set.shift(1).dropna()[3:], label='forecast of zt with dummy model')\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.title('Forecasted value of zt vs zt')\n",
    "plt.ylabel('zt')\n",
    "plt.xlabel('date')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d) Report the Mean-Squared Error for the selected model using only the hold-out sample of 34 observations to evaluate the forecast performance. Compare these statistics to those from the naive forecast. What model should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = sum((test_set[4:] - y_forecast_values) ** 2)\n",
    "mse_naive = sum((test_set[4:] - test_set.shift(1).dropna()[3:]) ** 2)\n",
    "print(mse_model, mse_naive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
