{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - MATH60837A\n",
    "William Bourque - 11359215\n",
    "\n",
    "Frederic Pelletier - 11359258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing dependencies (only needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. a) Plot the log of house prices through time. What does a change on y-axis i.e. log(HP_t) - log(HP_{t-1}) represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_HP'] = np.log(df['QCAR628BIS'])\n",
    "sns.lineplot(data=df, x='DATE', y='log_HP')\n",
    "plt.ylabel('Log of house prices')\n",
    "plt.title(\"log(HP_t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "log(HP_t) - log(HP_{t-1}) represents the percentage of gain (if positive) or loss (if negative) on house prices from time {t-1} to time {t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. b) Assume there is a deterministic linear time trend. Apply the transformation to stationarize z_t and plot the results (determinist trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df.shape[0]  # Number of observations\n",
    "trend = np.arange(1, T + 1)  # Linear time trend \n",
    "\n",
    "X = np.column_stack((np.ones(T), trend))  # Column of ones for intercept, trend as second column\n",
    "\n",
    "# Dependent variable\n",
    "Y = np.array(df['log_HP'])  # Assuming log_HP is the dependent variable in the DataFrame\n",
    "\n",
    "# Solve for B using the OLS formula\n",
    "B = np.linalg.lstsq(X, Y, rcond=None)[0]  #OLS solution\n",
    "\n",
    "# Calculate the detrended series\n",
    "df['detrend_HP'] = Y - np.dot(X, B)  \n",
    "\n",
    "print(\"Beta coefficients (B):\", B)\n",
    "print(df.head())\n",
    "\n",
    "# Plot the graph of the determinist trend deviation\n",
    "sns.lineplot(data=df, x='DATE', y='detrend_HP')\n",
    "plt.ylabel('Growth percentage')\n",
    "plt.title('Deterministic Trend Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "We can see from the graph that the deterministic trend does not seem to return a stationnarized series or to be white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Assume there is a stochastic time trend, i.e. a random walk. Apply the transformation required to stationarize z_t and plot the resulting series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_HP'] = df['log_HP'].pct_change() # Create a column of the pct change between each periods\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Plot of the log avariation assuming a stochastiv trend\n",
    "sns.lineplot(data=df, x='DATE', y='diff_HP')\n",
    "plt.ylabel('Growth Percentage')\n",
    "plt.title(\"Difference Series\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The stochastic trend series seems stationnary, there is also a possibility to be in presence of white noise. Further testing will be required to confirm or infirm both of these takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d) Analyze the sample autocorrelation functions to evaluate if the series are stationary. Which series would you choose to estimate a time-series model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_vector_deter = acf(df['detrend_HP'], nlags=20) # Autocorrelation determinist\n",
    "print(acf_vector_deter)\n",
    "acf_vector_stocha = acf(df['diff_HP'].iloc[1:], nlags=20) # Autocorrelation stochastic\n",
    "print(acf_vector_stocha)\n",
    "\n",
    "plt.plot(acf_vector_deter, label='deterministic acf') # Plot of determinist autocorrelations\n",
    "plt.plot(acf_vector_stocha, label='stochastic acf') # Plot of stochastic autocorrelations\n",
    "plt.xlabel('lag')\n",
    "plt.ylabel('autocorrelation')\n",
    "plt.title('ACF for deterministic vs stochastic model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    " Stochastic hypothesis is better to estimate a time series model, the autocorrelations indicates stationarity and that there could be white noise. White noise and stationarity hypothesis is refused in the case of the deterministic linear time trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. e) Perform Lyung-Box test on the stochastic trend series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(df['diff_HP'].iloc[1:], lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "We reject the hypothesis that there is no autocorrelation between the observations of the stochastic trend time series. We can conclude that the series is not white noise. Althought it is not white noise, the autocorrelations of the stochastic trend time series suggests stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Estimate all 4 models by maximum likelihood, report the estimation results, and verify if the stationarity conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = df['diff_HP'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(1) model so we can use the statsmodel library\n",
    "model1 = ARIMA(yt, order=(1,0,0)) \n",
    "fitted_model1 = model1.fit()\n",
    "\n",
    "phi1 = fitted_model1.arparams[0]\n",
    "delta = fitted_model1.params['const']\n",
    "variance = fitted_model1.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "if abs(phi1) < 1:\n",
    "    print(f'Since |{phi1}| < 1, the model is stationary')\n",
    "else:\n",
    "    print(f'Since |{phi1}| > 1, the model is not stationary')\n",
    "print(fitted_model1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the phi1 parameter is less than 1 in absolute value, the model is stationary. Furthermore, the p-values obtained from the t-tests on the parameters is less than 0.05, meaning we can reject the null hypothesis that the parameters are equal to 0. There is therefore statistically significant evidence that the parameters contribute meaningfully to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(2) model so we can use the statsmodel library\n",
    "model2 = ARIMA(yt, order=(2,0,0)) \n",
    "fitted_model2 = model2.fit()\n",
    "\n",
    "phi1 = fitted_model2.arparams[0]\n",
    "phi2 = fitted_model2.arparams[1]\n",
    "delta = fitted_model2.params['const']\n",
    "variance = fitted_model2.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model2.summary())\n",
    "phi_matrix = np.array([[phi1,phi2],[1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. Furthermore, since the p-value of the various t-tests done on the parameters are less than 0.01, there is strong statistical evidence that we can reject the null hypothesis, meaning the parameters contribute to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(3) model so we can use the statsmodel library\n",
    "model3 = ARIMA(yt, order=(3,0,0))\n",
    "fitted_model3 = model3.fit()\n",
    "\n",
    "phi1 = fitted_model3.arparams[0]\n",
    "phi2 = fitted_model3.arparams[1]\n",
    "phi3 = fitted_model3.arparams[2]\n",
    "delta = fitted_model3.params['const']\n",
    "variance = fitted_model3.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}), (phi3, {phi3}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model3.summary())\n",
    "phi_matrix = np.array([[phi1,phi2,phi3],[1,0,0], [0,1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. Furthermore, since the p-value of the various t-tests done on the parameters are less than 0.05, there is strong statistical evidence that we can reject the null hypothesis, meaning the parameters contribute to the model meaningfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an AR(3) model but with a fixed value of 0 for phi2\n",
    "model4 = ARIMA(yt, order=(3,0,0), enforce_stationarity=False) #needed for us to be able to fix a parameter\n",
    "with model4.fix_params({'ar.L2': 0}):\n",
    "    fitted_model4 = model4.fit()\n",
    "\n",
    "phi1 = fitted_model4.arparams[0]\n",
    "phi2 = fitted_model4.arparams[1]\n",
    "phi3 = fitted_model4.arparams[2]\n",
    "delta = fitted_model4.params['const']\n",
    "variance = fitted_model4.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}), (phi3, {phi3}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model4.summary())\n",
    "phi_matrix = np.array([[phi1,phi2,phi3],[1,0,0], [0,1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. However, the p-value for the constant parameter is > 0.05, which means there is weak statistical evidence that this parameter contributes meaningfully to the model. The other parameters seem to contribute meaningfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Perform 2 likelihood ratio tests to justify the selection of models. The first test should discriminate between model (1) and (2), the second one should discriminate between model (3) and (4). Finally, choose one of the two remaining models using the BIC criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first define a function to help us perform the test\n",
    "def likelihood_ratio_test(l1,l0,k, alpha):\n",
    "    statistic = 2*(l1 - l0)\n",
    "    critical_value = chi2.ppf(1 - alpha, k)\n",
    "    print(f'{statistic=}, {critical_value=}')\n",
    "    print('p-value:',1 - chi2.cdf(statistic, k)) # P(chi2 > statistic)\n",
    "    return statistic > critical_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_from_first_test = None\n",
    "model_from_second_test = None\n",
    "can_reject_null = likelihood_ratio_test(fitted_model2.llf, fitted_model1.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the model 2')\n",
    "    model_from_first_test = fitted_model2\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the model 1')\n",
    "    model_from_first_test = fitted_model1\n",
    "\n",
    "can_reject_null = likelihood_ratio_test(fitted_model3.llf, fitted_model4.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the model 3')\n",
    "    model_from_second_test = fitted_model3\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the model 4')\n",
    "    model_from_second_test = fitted_model4\n",
    "\n",
    "print(f'BIC values of selected models:{model_from_first_test.bic,model_from_second_test.bic}')\n",
    "chosen_model = model_from_first_test if model_from_first_test.bic < model_from_second_test.bic else model_from_second_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "Since the BIC value is smaller for model 3, we pick it over model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c) Evaluate the white noise hypothesis for the residual of the chosen model. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform Ljung-Box on the residuals\n",
    "residuals = chosen_model.resid\n",
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "acf(residuals,nlags=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "We can reject the null hypothesis for all the lags except the first 3. This indicates that the residuals are autocorrelated as we increased the lag and are therefore not white noise. Our model is therefore a poor fit for the data that we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Dynamic response and forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a) For the chosen model evaluate the dynamic response for an horizon of 10 periods following a negative shock of size sigma = 1.15 occuring at the first period of the horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chosen_model.impulse_responses(10,[-1.15]), label='response')\n",
    "plt.xlabel('Periods')\n",
    "plt.ylabel('Response value')\n",
    "plt.title('Dynamic response following a shock of -1.5')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "We can see the response trending to 0 which means the shock is transitory. This can be explained by the fact that the series is stationary. Even though we do not have white noise, the derivative Y_{t+i} given U_t remains the same as a regular AR(3). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.b) Forecasting: Split the sample into a training sample and a holdout sample. The holdout sample should consist of the last 34 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = yt[:-34]\n",
    "test_set = yt[-34:] #last 34 data points\n",
    "model3_train = ARIMA(training_set,order=(3,0,0))\n",
    "fitted_model3_train = model3_train.fit()\n",
    "\n",
    "\n",
    "# y{t+5} = delta + phi1 * y{t+4} + phi2 * y{t+3} + phi3 * y{t+2}\n",
    "# y{t+4} = delta + phi1 * y{t+3} + phi2 * y{t+2} + phi3 * y{t+1}\n",
    "# y{t+3} = delta + phi1 * y{t+2} + phi2 * y{t+1} + phi3 * y{t}\n",
    "# forecast of y{t+5} given y{t+2}, y{t+1}, y{t}\n",
    "\n",
    "phi1 = fitted_model3_train.arparams[0]\n",
    "phi2 = fitted_model3_train.arparams[1]\n",
    "phi3 = fitted_model3_train.arparams[2]\n",
    "delta = fitted_model3_train.params['const']\n",
    "forecasts = []\n",
    "\n",
    "for i in range(34 - 2):\n",
    "    y_t3 = delta + phi1 * test_set.iloc[i+2] + phi2 * test_set.iloc[i+1] + phi3 * test_set.iloc[i]\n",
    "    y_t4 = delta + phi1 * y_t3 + phi2 * test_set.iloc[i+2] + phi3 * test_set.iloc[i+1] \n",
    "    y_t5 = delta + phi1 * y_t4 + phi2 * y_t3 + phi3 * test_set.iloc[i+2]\n",
    "    forecasts.append(y_t5)\n",
    "forecasts_df = pd.DataFrame({'forecast': forecasts})\n",
    "forecasts_df.index = test_set.index[2:]\n",
    "print(test_set.mean())\n",
    "plt.plot(forecasts_df, label='forecast')\n",
    "plt.plot(test_set, label='true value')\n",
    "plt.xlabel('DATE')\n",
    "plt.ylabel('Growth percentage')\n",
    "plt.title('Growth percentage over time of House prices: forecast vs. true value')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The forecast oscillates around the mean which is approximately 0.0017, which is expected, and it captures some of the volatility of the data, however without much success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.c) Calculate two criteria of forecast quality: the Mean Errors and the Mean Absolute Errors associated with the forecasts of step 3.b). Which of the two criteria is larger and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = (forecasts - test_set[2:]).mean()\n",
    "abs_mean_error = (forecasts - test_set[2:]).abs().mean()\n",
    "print(f'mean error: {mean_error}, mean absolute error: {abs_mean_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The mean absolute error is bigger (an order of magnitute larger) since the positive and negative errors will cancel out in the mean error computation, resulting in a potentially lower value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
