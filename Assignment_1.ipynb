{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installing dependencies (only needed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.set_index('DATE', inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Econometrics Assignment 1\n",
    "\n",
    "Part 1 - Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. a) Plot the log of house prices through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_HP'] = np.log(df['QCAR628BIS'])\n",
    "sns.lineplot(data=df, x='DATE', y='log_HP')\n",
    "plt.title(\"log(HP_t)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "log(HP_t) - log(HP_{t-1}) represents the percentage of gain (if positive) or loss (if negative) on house prices from time {t-1} to time {t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. b) Apply the transformation to stationarize z_t and plot the results (determinist trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df.shape[0]  # Number of observations\n",
    "trend = np.arange(1, T + 1)  # Linear time trend \n",
    "\n",
    "X = np.column_stack((np.ones(T), trend))  # Column of ones for intercept, trend as second column\n",
    "\n",
    "# Dependent variable\n",
    "Y = np.array(df['log_HP'])  # Assuming log_HP is the dependent variable in the DataFrame\n",
    "\n",
    "# Solve for B using the OLS formula\n",
    "B = np.linalg.lstsq(X, Y, rcond=None)[0]  #OLS solution\n",
    "\n",
    "# Calculate the detrended series\n",
    "df['detrend_HP'] = Y - np.dot(X, B)  \n",
    "\n",
    "print(\"Beta coefficients (B):\", B)\n",
    "print(df.head())\n",
    "\n",
    "# Plot the graph of the determinist trend deviation\n",
    "sns.lineplot(data=df, x='DATE', y='detrend_HP')\n",
    "plt.title('Determinist Trend Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. c) Apply the transformation to stationarize z_t and plot the results (stochastic trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff_HP'] = df['log_HP'].pct_change() # Create a column of the pct change between each periods\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Plot of the log avariation assuming a stochastiv trend\n",
    "sns.lineplot(data=df, x='DATE', y='diff_HP')\n",
    "plt.title(\"Difference Series\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. d) Analyze the auto-corelation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_vector_deter = acf(df['detrend_HP'], nlags=20) # Autocorrelation determinist\n",
    "print(acf_vector_deter)\n",
    "acf_vector_stocha = acf(df['diff_HP'].iloc[1:], nlags=20) # Autocorrelation stochastic\n",
    "print(acf_vector_stocha)\n",
    "\n",
    "plt.plot(acf_vector_deter) # Plot of determinist autocorrelations\n",
    "plt.show()\n",
    "plt.plot(acf_vector_stocha) # Plot of stochastic autocorrelations\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation : Stochastic hypothesis is better to to estimate a time series model, the auto-correlation goes to 0 much faster which indicates that there could be white noise. White noise hypothesis is refused in the case od the deterministic trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. e) Perform Lyung-Box test on the stochastic trend series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(df['diff_HP'].iloc[1:], lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation : We reject the hypothesis that there is correlation between the observation of the stochastic trend series. We can conclude that the series is stationnary and white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a) Estimate all 4 models by maximum likelihood, report the estimation results, and verify if the stationarity conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = df['diff_HP'].asfreq('QS').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(1) model so we can use the statsmodel library\n",
    "model1 = ARIMA(yt, order=(1,0,0), enforce_stationarity=False)\n",
    "fitted_model1 = model1.fit()\n",
    "\n",
    "phi1 = fitted_model1.arparams[0]\n",
    "delta = fitted_model1.params['const']\n",
    "variance = fitted_model1.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "if abs(phi1) < 1:\n",
    "    print(f'Since |{phi1}| < 1, the model is stationary')\n",
    "else:\n",
    "    print(f'Since |{phi1}| > 1, the model is not stationary')\n",
    "print(fitted_model1.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the phi1 parameter is less than 1 in absolute value, the model is stationary. Furthermore, the p-values obtained from the t-tests on the parameters is less than 0.05, meaning we can reject the null hypothesis that the parameters are equal to 0. There is therefore statistically significant evidence that the parameters contribute meaningfully to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(2) model so we can use the statsmodel library\n",
    "model2 = ARIMA(yt, order=(2,0,0), enforce_stationarity=False)\n",
    "fitted_model2 = model2.fit()\n",
    "\n",
    "phi1 = fitted_model2.arparams[0]\n",
    "phi2 = fitted_model2.arparams[1]\n",
    "delta = fitted_model2.params['const']\n",
    "variance = fitted_model2.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model2.summary())\n",
    "phi_matrix = np.array([[phi1,phi2],[1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. Furthermore, since the p-value of the various t-tests done on the parameters are less than 0.01, there is strong statistical evidence that we can reject the null hypothesis, meaning the parameters contribute to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a regular AR(3) model so we can use the statsmodel library\n",
    "model3 = ARIMA(yt, order=(3,0,0), enforce_stationarity=False)\n",
    "fitted_model3 = model3.fit()\n",
    "\n",
    "phi1 = fitted_model3.arparams[0]\n",
    "phi2 = fitted_model3.arparams[1]\n",
    "phi3 = fitted_model3.arparams[2]\n",
    "delta = fitted_model3.params['const']\n",
    "variance = fitted_model3.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}), (phi3, {phi3}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model3.summary())\n",
    "phi_matrix = np.array([[phi1,phi2,phi3],[1,0,0], [0,1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. Furthermore, since the p-value of the various t-tests done on the parameters are less than 0.05, there is strong statistical evidence that we can reject the null hypothesis, meaning the parameters contribute to the model meaningfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an AR(3) model but with a fixed value of 0 for phi2\n",
    "model4 = ARIMA(yt, order=(3,0,0), enforce_stationarity=False)\n",
    "with model4.fix_params({'ar.L2': 0}):\n",
    "    fitted_model4 = model4.fit()\n",
    "\n",
    "phi1 = fitted_model4.arparams[0]\n",
    "phi2 = fitted_model4.arparams[1]\n",
    "phi3 = fitted_model4.arparams[2]\n",
    "delta = fitted_model4.params['const']\n",
    "variance = fitted_model4.params['sigma2']\n",
    "\n",
    "\n",
    "print(f'fitter parameters: (phi1, {phi1}), (phi2, {phi2}), (phi3, {phi3}) (delta, {delta}), (sigma,{np.sqrt(variance)})')\n",
    "print(fitted_model4.summary())\n",
    "phi_matrix = np.array([[phi1,phi2,phi3],[1,0,0], [0,1,0]])\n",
    "eigenvalues,_ = np.linalg.eig(phi_matrix)\n",
    "print(f'The eigenvalues are {eigenvalues}')\n",
    "for eigenvalue in eigenvalues:\n",
    "    print(f'module of {eigenvalue} is {np.abs(eigenvalue)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Given that the module of the eigenvalues are less than 1, we can conclude that the process is stationary. However, the p-value for the constant parameter is > 0.05, which means there is weak statistical evidence that this parameter contributes meaningfully to the model. The other parameters seem to contribute meaningfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b) Perform 2 likelihood ratio tests to justify the selection of models. The first test should discriminate between model (1) and (2), the second one should discriminate between model (3) and (4). Finally, choose one of the two remaining models using the BIC criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first define a function to help us perform the test\n",
    "def likelihood_ratio_test(l1,l0,k, alpha):\n",
    "    statistic = 2*(l1 - l0)\n",
    "    critical_value = chi2.ppf(1 - alpha, k)\n",
    "    print(f'{statistic=}, {critical_value=}')\n",
    "    print('p-value:',1 - chi2.cdf(statistic, k)) # P(chi2 > statistic)\n",
    "    return statistic > critical_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_from_first_test = None\n",
    "model_from_second_test = None\n",
    "can_reject_null = likelihood_ratio_test(fitted_model2.llf, fitted_model1.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the model 2')\n",
    "    model_from_first_test = fitted_model2\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the model 1')\n",
    "    model_from_first_test = fitted_model1\n",
    "\n",
    "can_reject_null = likelihood_ratio_test(fitted_model3.llf, fitted_model4.llf, 1, 0.05)\n",
    "if can_reject_null:\n",
    "    print('we can reject the null hypothesis, meaning we pick the model 3')\n",
    "    model_from_second_test = fitted_model3\n",
    "else:\n",
    "    print('we cannot reject the null hypothesis, meaning we pick the model 4')\n",
    "    model_from_second_test = fitted_model4\n",
    "\n",
    "print(f'BIC values of selected models:{model_from_first_test.bic,model_from_second_test.bic}')\n",
    "chosen_model = model_from_first_test if model_from_first_test.bic < model_from_second_test.bic else model_from_second_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation \n",
    "Since the BIC value is smaller for model 1, we pick it over model 3. It makes sense since model 1 has less parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c) Evaluate the white noise hypothesis for the residual of the chosen model. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform Ljung-Box on the residuals\n",
    "residuals = chosen_model.resid\n",
    "lags = range(1, 19)  # Creat a vector for lags 1 to 18\n",
    "\n",
    "# Perform the Ljung-Box Q-test\n",
    "lbq_result = acorr_ljungbox(residuals, lags=lags, return_df=True)\n",
    "\n",
    "p_values = lbq_result['lb_pvalue']\n",
    "test_statistics = lbq_result['lb_stat']\n",
    "h1 = (p_values < 0.05).astype(int)  # Binary decision rule (1 = reject null hypothesis)\n",
    "\n",
    "# Print the results\n",
    "print(\"Decision Rule (h1):\", h1.values)\n",
    "print(\"P-Values:\", p_values.values)\n",
    "print(\"Test Statistics:\", test_statistics.values)\n",
    "acf(residuals,nlags=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "We can reject the null hypothesis for all the lags except 1. This indicates that the residuals are autocorrelated and are therefore not white noise. Our model is therefore a poor fit for the data that we have"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
